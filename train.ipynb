{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pku_autonomous_driving import io, util, dataset, resnet, centernet, training, graphics, transform, const, geometry\n",
    "\n",
    "import importlib\n",
    "importlib.reload(geometry)\n",
    "importlib.reload(io)\n",
    "importlib.reload(util)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(resnet)\n",
    "importlib.reload(centernet)\n",
    "importlib.reload(training)\n",
    "importlib.reload(graphics)\n",
    "importlib.reload(transform)\n",
    "importlib.reload(const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from pku_autonomous_driving.transform import CropBottomHalf, CropFar, PadByMean, Resize, Normalize, DropPointsAtOutOfScreen, CreateMaskAndRegr, ToCHWOrder\n",
    "from pku_autonomous_driving.const import IMG_WIDTH, IMG_HEIGHT, MODEL_SCALE\n",
    "\n",
    "near_transform = torchvision.transforms.Compose([\n",
    "    CropBottomHalf(),\n",
    "    #PadByMean(),\n",
    "    Resize(IMG_WIDTH, IMG_HEIGHT),\n",
    "    Normalize(),\n",
    "    DropPointsAtOutOfScreen(IMG_WIDTH, IMG_HEIGHT),\n",
    "    CreateMaskAndRegr(IMG_WIDTH, IMG_HEIGHT, MODEL_SCALE),\n",
    "    ToCHWOrder()\n",
    "])\n",
    "\n",
    "far_transform = torchvision.transforms.Compose([\n",
    "    CropFar(IMG_WIDTH, IMG_HEIGHT),\n",
    "    Normalize(),\n",
    "    DropPointsAtOutOfScreen(IMG_WIDTH, IMG_HEIGHT),\n",
    "    CreateMaskAndRegr(IMG_WIDTH, IMG_HEIGHT, MODEL_SCALE),\n",
    "    ToCHWOrder()\n",
    "])\n",
    "\n",
    "transforms = {\n",
    "    'NEAR': near_transform,\n",
    "    'FAR': far_transform\n",
    "}\n",
    "\n",
    "train_transform = transforms[os.environ.get(\"TRANSFORM_TYPE\", \"NEAR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pku_autonomous_driving.dataset import CarDataset, create_data_loader\n",
    "from pku_autonomous_driving.const import BATCH_SIZE\n",
    "\n",
    "train, dev = io.load_train_data()\n",
    "train = train[:4]\n",
    "dev = dev[:4]\n",
    "\n",
    "train_dataset = CarDataset(train, transform=train_transform)\n",
    "dev_dataset = CarDataset(dev, transform=train_transform)\n",
    "\n",
    "train_loader = create_data_loader(train_dataset, batch_size=BATCH_SIZE)\n",
    "dev_loader = create_data_loader(dev_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = train_loader.dataset[0]\n",
    "img, mask, regr = data[\"img\"], data[\"mask\"], data[\"regr\"]\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(np.rollaxis(img, 0, 3))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(regr[-2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from apex import amp\n",
    "\n",
    "base_model = resnet.resnext50_32x4d(pretrained=False)\n",
    "model = centernet.CentResnet(base_model, 8)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "#optimizer =  RAdam(model.parameters(), lr = 0.001)\n",
    "\n",
    "#model, optimizer = amp.initialize(model, optimizer)\n",
    "#model = util.BN_convert_float(model.half())\n",
    "#model = util.network_to_half(model)\n",
    "setup_kwargs = {\n",
    "    \"model\": model,\n",
    "    \"device\": device,\n",
    "    \"path\" : Path(\"./res_mask_1/resnext50.pth\")\n",
    "}\n",
    "\n",
    "util.setup_model(**setup_kwargs)\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = int(os.environ.get(\"N_EPOCHS\", 6))\n",
    "n_epochs = 1\n",
    "\n",
    "try:\n",
    "    history = pickle.load(Path(os.environ[\"INITIAL_HISTORY\"]).open('rb'))\n",
    "    beg_epoch = math.ceil(history.index[-1])\n",
    "except:\n",
    "    history = pd.DataFrame()\n",
    "    beg_epoch = 0\n",
    "end_epoch = beg_epoch + n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=max(n_epochs, 10) * len(train_loader) // 3, gamma=0.1)\n",
    "\n",
    "best_dev_loss = np.inf\n",
    "for epoch in range(beg_epoch, end_epoch):\n",
    "    training.clean_up()\n",
    "    training.train(model, optimizer, exp_lr_scheduler, train_loader, epoch, device, history)\n",
    "    training.evaluate(model, dev_loader, epoch, device, history)\n",
    "    training.save_checkpoint(model, optimizer, history)\n",
    "\n",
    "    cur_dev_loss = history['dev_loss'].dropna().iloc[-1]\n",
    "    if cur_dev_loss < best_dev_loss:\n",
    "        torch.save({\"model\": model.state_dict()}, './resnext50.pth')\n",
    "        best_dev_loss = cur_dev_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['train_loss'].iloc[:].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = history.dropna()['mask_loss']\n",
    "plt.plot(series1.index, series1 ,label = 'mask loss');\n",
    "series2 = history.dropna()['regr_loss']\n",
    "plt.plot(series2.index, 30*series2,label = 'regr loss');\n",
    "series3 = history.dropna()['dev_loss']\n",
    "plt.plot(series3.index, series3,label = 'dev loss');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = history.dropna()['dev_loss']\n",
    "plt.scatter(series.index, series);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_loader.dataset[0]\n",
    "img, mask, regr = data[\"img\"], data[\"mask\"], data[\"regr\"]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Input image')\n",
    "plt.imshow(np.rollaxis(img, 0, 3))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Ground truth mask')\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "\n",
    "output = model(torch.tensor(img[None]).to(device))\n",
    "logits = output[0,0].data.cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Model predictions')\n",
    "plt.imshow(logits)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title('Model predictions thresholded')\n",
    "plt.imshow(logits > 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "training.clean_up()\n",
    "for idx in range(4):\n",
    "    data = dev_loader.dataset[idx]\n",
    "    img, mask, regr = data[\"img\"], data[\"mask\"], data[\"regr\"]\n",
    "    output = model(torch.tensor(img[None]).to(device)).data.cpu().numpy()\n",
    "\n",
    "    coords_pred = util.extract_coords(data, output[0])\n",
    "    coords_true = util.extract_coords(data)\n",
    "\n",
    "    img = io.load_image(dev_loader.dataset.dataset[idx].image_id)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(30,30))\n",
    "    axes[0].set_title('Ground truth')\n",
    "    axes[0].imshow(graphics.draw_coords(img, coords_true))\n",
    "    axes[1].set_title('Prediction')\n",
    "    axes[1].imshow(graphics.draw_coords(img, coords_pred))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train_loader.dataset[0][\"data\"][6]\n",
    "id = train_loader.dataset.dataset[0].image_id\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = geometry.proj_world_to_screen(np.array([[d['x'], d['y'], d['z']]])).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.load_image(id)\n",
    "img[p[0,1]-50:p[0,1]+50, p[0,0]-50:p[0,0]+50,:] = (255, 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = io.load_camera_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov = 2 * math.atan(img.shape[1] / (2 * cm[0,0]))\n",
    "fov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov / math.pi * 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = np.array([[d['x'], d[\"y\"], d['z']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dp = geometry.proj_world_to_screen(dp).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.pi / 2 - math.atan((proj_dp[0, 0] - img.shape[1] // 2) / cm[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = proj_dp[0,0] - img.shape[1] // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_theta = math.pi / 2 + math.atan(diff / cm[0,0])\n",
    "ray_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_theta / math.pi * 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_pitch = calc_ray_pitch(proj_dp[0, 0], img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_pitch / math.pi * 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_radian(theta, minv=0, maxv = (2 * math.pi)):\n",
    "    if theta < minv:\n",
    "        return clamp_radian(theta + 2 * math.pi, minv, maxv)\n",
    "    elif maxv <= theta:\n",
    "        return clamp_radian(theta - 2 * math.pi, minv, maxv)\n",
    "    return theta\n",
    "\n",
    "def calc_global_pitch(org_pitch):\n",
    "    return clamp_radian(org_pitch + math.pi / 2)\n",
    "\n",
    "def calc_org_pitch(global_pitch):\n",
    "    return clamp_radian(global_pitch - math.pi / 2, -math.pi, math.pi)\n",
    "\n",
    "def calc_ray_pitch(x, img_width, camera_matrix=io.load_camera_matrix()):\n",
    "    diff = x - img_width // 2\n",
    "    ray_pitch = math.pi / 2 + math.atan(diff / cm[0,0])\n",
    "    return ray_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pitch = calc_global_pitch(d[\"pitch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_offset = global_pitch - ray_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_pitch_to_ray(d[\"pitch\"], proj_dp[0, 0], img.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = calc_global_pitch(d[\"pitch\"])\n",
    "rp = calc_ray_pitch(proj_dp[0, 0], img.shape[1])\n",
    "pitch_to_ray = gp - rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp2 = pitch_to_ray + rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_org_pitch(gp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"pitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.pi / 2 - math.atan(d[\"x\"] / d[\"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_ray_pitch(img.shape[1], img.shape[1]) / math.pi * 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_ray_pitch(0, img.shape[1]) / math.pi * 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "126.28613099510488 + 53.7138690048951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.pi / 2 - math.atan((0 - img.shape[1] // 2) / cm[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.atan(- img.shape[1] / (2 * cm[0, 0])) / math.pi * 180 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * math.atan(img.shape[1] / (2 * cm[0,0])) / math.pi * 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
